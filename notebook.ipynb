{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2026-02-02T20:10:15.541071Z",
     "start_time": "2026-02-02T20:10:15.501205Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import os"
   ],
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-02T20:10:26.173469Z",
     "start_time": "2026-02-02T20:10:26.122879Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "\n",
    "data = np.load(\"data/candidate_dataset.npz\")\n",
    "print(data.files)"
   ],
   "id": "c343aa696ea58bc5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['x_train', 'y_train', 'x_val', 'y_val']\n"
     ]
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-02T20:12:31.797470Z",
     "start_time": "2026-02-02T20:12:31.224293Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data = np.load(\"data/candidate_dataset.npz\")\n",
    "\n",
    "X_train = data[\"x_train\"]\n",
    "y_train = data[\"y_train\"]\n",
    "X_val   = data[\"x_val\"]\n",
    "y_val   = data[\"y_val\"]\n",
    "\n",
    "# ðŸ”¥ FIX: convert one-hot â†’ class index\n",
    "if y_train.ndim > 1:\n",
    "    y_train = np.argmax(y_train, axis=1)\n",
    "\n",
    "if y_val.ndim > 1:\n",
    "    y_val = np.argmax(y_val, axis=1)\n",
    "\n",
    "print(\"Train:\", X_train.shape, y_train.shape)\n",
    "print(\"Val:\", X_val.shape, y_val.shape)\n"
   ],
   "id": "f642994b6e9ff9db",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (7007, 28, 28, 3) (7007,)\n",
      "Val: (1003, 28, 28, 3) (1003,)\n"
     ]
    }
   ],
   "execution_count": 35
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-02T20:12:39.818232Z",
     "start_time": "2026-02-02T20:12:39.750253Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class DermaDataset(Dataset):\n",
    "    def __init__(self, images, labels):\n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = self.images[idx]\n",
    "\n",
    "        # If image has 3 channels â†’ convert to grayscale\n",
    "        if x.ndim == 3 and x.shape[-1] == 3:\n",
    "            x = x.mean(axis=-1)\n",
    "\n",
    "        x = torch.tensor(x, dtype=torch.float32).unsqueeze(0) / 255.0\n",
    "        y = torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "\n",
    "        return x, y"
   ],
   "id": "aa059c31d85e2249",
   "outputs": [],
   "execution_count": 36
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-02T20:12:42.780008Z",
     "start_time": "2026-02-02T20:12:42.631992Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_ds = DermaDataset(X_train, y_train)\n",
    "val_ds   = DermaDataset(X_val, y_val)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=64, shuffle=True)\n",
    "val_loader   = DataLoader(val_ds, batch_size=64, shuffle=False)"
   ],
   "id": "89c2a49b18c04fb1",
   "outputs": [],
   "execution_count": 37
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-02T20:12:44.621143Z",
     "start_time": "2026-02-02T20:12:44.584621Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class CustomCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Dropout(0.25),\n",
    "\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.AdaptiveAvgPool2d(1)\n",
    "        )\n",
    "\n",
    "        self.classifier = nn.Linear(128, 7)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        return self.classifier(x)"
   ],
   "id": "b02aecb533c920ad",
   "outputs": [],
   "execution_count": 38
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-02T20:12:47.906890Z",
     "start_time": "2026-02-02T20:12:47.710473Z"
    }
   },
   "cell_type": "code",
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "model = CustomCNN().to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3)"
   ],
   "id": "c7c0af1812fd5c61",
   "outputs": [],
   "execution_count": 39
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-02T20:13:38.745152Z",
     "start_time": "2026-02-02T20:12:49.197275Z"
    }
   },
   "cell_type": "code",
   "source": [
    "os.makedirs(\"model\", exist_ok=True)\n",
    "\n",
    "epochs = 15\n",
    "train_losses = []\n",
    "val_accuracies = []\n",
    "best_acc = 0.0\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for x, y in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs}\"):\n",
    "        x, y = x.to(device), y.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(x)\n",
    "        loss = criterion(outputs, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    avg_loss = running_loss / len(train_loader)\n",
    "    train_losses.append(avg_loss)\n",
    "\n",
    "    model.eval()\n",
    "    preds_all, y_all = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x, y in val_loader:\n",
    "            x = x.to(device)\n",
    "            preds = model(x).argmax(1).cpu().numpy()\n",
    "            preds_all.extend(preds)\n",
    "            y_all.extend(y.numpy())\n",
    "\n",
    "    acc = accuracy_score(y_all, preds_all)\n",
    "    val_accuracies.append(acc)\n",
    "\n",
    "    if acc > best_acc:\n",
    "        best_acc = acc\n",
    "        torch.save(model.state_dict(), \"model/best_model.pth\")\n",
    "\n",
    "    print(f\"Epoch {epoch+1} | Loss: {avg_loss:.4f} | Val Acc: {acc:.4f}\")"
   ],
   "id": "9cb0c6e7a1a7d941",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/15: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 110/110 [00:35<00:00,  3.12it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[40], line 41\u001B[0m\n\u001B[0;32m     39\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m acc \u001B[38;5;241m>\u001B[39m best_acc:\n\u001B[0;32m     40\u001B[0m     best_acc \u001B[38;5;241m=\u001B[39m acc\n\u001B[1;32m---> 41\u001B[0m     \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msave\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstate_dict\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mmodel/best_model.pth\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m     43\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mEpoch \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mepoch\u001B[38;5;241m+\u001B[39m\u001B[38;5;241m1\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m | Loss: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mavg_loss\u001B[38;5;132;01m:\u001B[39;00m\u001B[38;5;124m.4f\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m | Val Acc: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00macc\u001B[38;5;132;01m:\u001B[39;00m\u001B[38;5;124m.4f\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[1;32m~\\PycharmProjects\\MaxHealth_assessment\\.venv\\lib\\site-packages\\torch\\serialization.py:976\u001B[0m, in \u001B[0;36msave\u001B[1;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization, _disable_byteorder_record)\u001B[0m\n\u001B[0;32m    973\u001B[0m     f \u001B[38;5;241m=\u001B[39m os\u001B[38;5;241m.\u001B[39mfspath(f)\n\u001B[0;32m    975\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m _use_new_zipfile_serialization:\n\u001B[1;32m--> 976\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m \u001B[43m_open_zipfile_writer\u001B[49m\u001B[43m(\u001B[49m\u001B[43mf\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mas\u001B[39;00m opened_zipfile:\n\u001B[0;32m    977\u001B[0m         _save(\n\u001B[0;32m    978\u001B[0m             obj,\n\u001B[0;32m    979\u001B[0m             opened_zipfile,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    982\u001B[0m             _disable_byteorder_record,\n\u001B[0;32m    983\u001B[0m         )\n\u001B[0;32m    984\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m\n",
      "File \u001B[1;32m~\\PycharmProjects\\MaxHealth_assessment\\.venv\\lib\\site-packages\\torch\\serialization.py:838\u001B[0m, in \u001B[0;36m_open_zipfile_writer\u001B[1;34m(name_or_buffer)\u001B[0m\n\u001B[0;32m    836\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    837\u001B[0m     container \u001B[38;5;241m=\u001B[39m _open_zipfile_writer_buffer\n\u001B[1;32m--> 838\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mcontainer\u001B[49m\u001B[43m(\u001B[49m\u001B[43mname_or_buffer\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\PycharmProjects\\MaxHealth_assessment\\.venv\\lib\\site-packages\\torch\\serialization.py:803\u001B[0m, in \u001B[0;36m_open_zipfile_writer_file.__init__\u001B[1;34m(self, name)\u001B[0m\n\u001B[0;32m    795\u001B[0m     \u001B[38;5;28msuper\u001B[39m()\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__init__\u001B[39m(\n\u001B[0;32m    796\u001B[0m         torch\u001B[38;5;241m.\u001B[39m_C\u001B[38;5;241m.\u001B[39mPyTorchFileWriter(  \u001B[38;5;66;03m# pyrefly: ignore  # no-matching-overload\u001B[39;00m\n\u001B[0;32m    797\u001B[0m             \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfile_stream, get_crc32_options(), _get_storage_alignment()\n\u001B[0;32m    798\u001B[0m         )\n\u001B[0;32m    799\u001B[0m     )\n\u001B[0;32m    800\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    801\u001B[0m     \u001B[38;5;28msuper\u001B[39m()\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__init__\u001B[39m(\n\u001B[0;32m    802\u001B[0m         torch\u001B[38;5;241m.\u001B[39m_C\u001B[38;5;241m.\u001B[39mPyTorchFileWriter(\n\u001B[1;32m--> 803\u001B[0m             \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mname, \u001B[43mget_crc32_options\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m, _get_storage_alignment()\n\u001B[0;32m    804\u001B[0m         )\n\u001B[0;32m    805\u001B[0m     )\n",
      "File \u001B[1;32m~\\PycharmProjects\\MaxHealth_assessment\\.venv\\lib\\site-packages\\torch\\serialization.py:178\u001B[0m, in \u001B[0;36mget_crc32_options\u001B[1;34m()\u001B[0m\n\u001B[0;32m    172\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mget_crc32_options\u001B[39m() \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28mbool\u001B[39m:\n\u001B[0;32m    173\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    174\u001B[0m \u001B[38;5;124;03m    Get whether :func:`torch.save` computes and writes crc32 for each record.\u001B[39;00m\n\u001B[0;32m    175\u001B[0m \n\u001B[0;32m    176\u001B[0m \u001B[38;5;124;03m    Defaults to ``True``.\u001B[39;00m\n\u001B[0;32m    177\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m--> 178\u001B[0m     \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mtorch\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutils\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mserialization\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m config\n\u001B[0;32m    180\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m config\u001B[38;5;241m.\u001B[39msave\u001B[38;5;241m.\u001B[39mcompute_crc32\n",
      "File \u001B[1;32m<frozen importlib._bootstrap>:1027\u001B[0m, in \u001B[0;36m_find_and_load\u001B[1;34m(name, import_)\u001B[0m\n",
      "File \u001B[1;32m<frozen importlib._bootstrap>:1006\u001B[0m, in \u001B[0;36m_find_and_load_unlocked\u001B[1;34m(name, import_)\u001B[0m\n",
      "File \u001B[1;32m<frozen importlib._bootstrap>:674\u001B[0m, in \u001B[0;36m_load_unlocked\u001B[1;34m(spec)\u001B[0m\n",
      "File \u001B[1;32m<frozen importlib._bootstrap>:577\u001B[0m, in \u001B[0;36mmodule_from_spec\u001B[1;34m(spec)\u001B[0m\n",
      "File \u001B[1;32m<frozen importlib._bootstrap>:556\u001B[0m, in \u001B[0;36m_init_module_attrs\u001B[1;34m(spec, module, override)\u001B[0m\n",
      "File \u001B[1;32m<frozen importlib._bootstrap>:397\u001B[0m, in \u001B[0;36mcached\u001B[1;34m(self)\u001B[0m\n",
      "File \u001B[1;32m<frozen importlib._bootstrap_external>:510\u001B[0m, in \u001B[0;36m_get_cached\u001B[1;34m(filename)\u001B[0m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 40
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "plt.figure(figsize=(10,4))\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(train_losses)\n",
    "plt.title(\"Training Loss\")\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(val_accuracies)\n",
    "plt.title(\"Validation Accuracy\")\n",
    "\n",
    "plt.show()"
   ],
   "id": "b8d6f515d93f94d4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "\n",
    "class CustomCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, 3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.Conv2d(32, 64, 3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Dropout(0.25),\n",
    "\n",
    "            nn.Conv2d(64, 128, 3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.AdaptiveAvgPool2d(1)\n",
    "        )\n",
    "        self.classifier = nn.Linear(128, 7)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        return self.classifier(x)\n",
    "\n",
    "def evaluate(npz_path):\n",
    "    data = np.load(npz_path)\n",
    "\n",
    "    X = data[\"x_val\"]\n",
    "    y = data[\"y_val\"]\n",
    "\n",
    "    # RGB â†’ Grayscale\n",
    "    if X.ndim == 4 and X.shape[-1] == 3:\n",
    "        X = X.mean(axis=-1)\n",
    "\n",
    "    X = torch.tensor(X, dtype=torch.float32).unsqueeze(1) / 255.0\n",
    "\n",
    "    model = CustomCNN()\n",
    "    model.load_state_dict(torch.load(\"model/best_model.pth\", map_location=\"cpu\"))\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        preds = model(X).argmax(1).numpy()\n",
    "\n",
    "    acc = (preds == y).mean()\n",
    "    print(\"Accuracy:\", acc)"
   ],
   "id": "1f6987c0548ba5e6"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
